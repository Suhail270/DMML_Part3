{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,multilabel_confusion_matrix,roc_auc_score,roc_curve,auc,ConfusionMatrixDisplay,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all=pd.read_csv(\"CompleteDataSet/x_train_all.csv\")\n",
    "y_train_all=pd.read_csv(\"CompleteDataSet/y_train_all.csv\")\n",
    "x_test_all=pd.read_csv(\"CompleteDataSet/x_test_all.csv\")\n",
    "y_test_all=pd.read_csv(\"CompleteDataSet/y_test_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(Y_test,predicted):   \n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "\n",
    "    # Y_test_bin = label_binarize(Y_test, classes=[0, 1, 2,3,4,5,6,7,8,9])\n",
    "    # roc = roc_auc_score(Y_test_bin, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = (fp/(tn + fp), tp + fn)\n",
    "    tnr = (tn/(tn + fp), tp + fn)\n",
    "\n",
    "    # fpr, tpr, _ = roc_curve(Y_test_bin.ravel(), predicted_probs.ravel())\n",
    "\n",
    "\n",
    "    # auc_val = auc(fpr, tpr)\n",
    "    # plt.figure()\n",
    "    # plt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC (area = %0.2f)' % auc_val)\n",
    "    # plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.title('ROC Curve')\n",
    "    # plt.legend(loc=\"lower right\")\n",
    "    # plt.show()\n",
    "\n",
    "    # out=ConfusionMatrixDisplay(conf_matrix,display_labels=gnb.classes_)\n",
    "    # out.plot()\n",
    "    # plt.show()\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    print(\"Specificity:\", tnr)\n",
    "    # print(\"False Positive Rate:\", fpr)\n",
    "    # print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_10(input,output):\n",
    "    kf = KFold(n_splits=10) \n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    accuracy_scores = []\n",
    "    for train_index, test_index in kf.split(input):\n",
    "        print(\"Train:\", len( train_index), \"Validation:\",len(test_index))\n",
    "        X_train, X_test = input.iloc[train_index], input.iloc[test_index] \n",
    "        y_train, y_test = output.iloc[train_index], output.iloc[test_index]\n",
    "        dt_classifier.fit(X_train, y_train)\n",
    "        pred=dt_classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    average_accuracy = sum(accuracy_scores) / 10\n",
    "\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9690, 2304)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9690, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Train: 8721 Validation: 969\n",
      "Average Accuracy: 0.4893704850361197\n"
     ]
    }
   ],
   "source": [
    "kfold_10(x_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X_train,X_test,y_test,y_train):\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    dt_classifier.fit(X_train,y_train)\n",
    "    pred=dt_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    metric(y_test,pred)\n",
    "    print(\"The Accuracy is:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6851132686084143\n",
      "F1 Score: 0.6881416018187559\n",
      "Precision: 0.6830429990865233\n",
      "Recall/Sensitivity/True Positive Rate: 0.6851132686084143\n",
      "Specificity: (array([0.98316832, 0.90168776, 0.91282051, 0.95265152, 0.91934156,\n",
      "       0.98910891, 0.98566667, 0.98976898, 0.98809524, 0.99266667]), array([ 60, 720, 750, 450, 660,  60,  90,  60, 150,  90], dtype=int64))\n",
      "Confusion Matrix:\n",
      " [[ 18  19   1   2  22   0   1   0   6   0]\n",
      " [ 10 557  71  24  58   0  10  23  18  19]\n",
      " [  7  61 566  63  30   1   5   6  16  15]\n",
      " [  3   9  41 308  39   7  10   1  14   1]\n",
      " [ 17  60  57  27 473  23   1   0  11   0]\n",
      " [  0   0   4   0   7  29   8   9   3   2]\n",
      " [  3   2   1  12  11   0  40   3  11   0]\n",
      " [  2   5   6   4   7   0   0  15   6   1]\n",
      " [  0   4   1   5   6   0  14   0  64   5]\n",
      " [  0   3   2   5   7   0   1   3   1  47]]\n",
      "The Accuracy is: 0.6851132686084143\n"
     ]
    }
   ],
   "source": [
    "train_test_split(x_train_all,x_test_all,y_test_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
